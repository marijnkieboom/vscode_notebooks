{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\"\"\"Select device (GPU)\"\"\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Selected device:', device)\n",
    "\n",
    "\"\"\"Load Tokens from CSV\"\"\"\n",
    "df = pd.read_csv(\n",
    "    '../data-sets/Zinparen in Engels-Nederlands - 2024-10-21.csv',\n",
    "    names=['ENG_TOKENS', 'NLD_TOKENS'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows from file: 152194\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENG_TOKENS</th>\n",
       "      <th>NLD_TOKENS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENG_TOKENS</td>\n",
       "      <td>NLD_TOKENS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;SOS&gt; Let 's try something . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; Laten we iets proberen ! &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;SOS&gt; Let 's try something . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; Laat ons iets proberen . &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;SOS&gt; I have to go to sleep . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; Ik moet gaan slapen . &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;SOS&gt; Today is June 18th and it is Muiriel 's ...</td>\n",
       "      <td>&lt;SOS&gt; Vandaag is het 18 juni en het is de verj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153805</th>\n",
       "      <td>&lt;SOS&gt; Cotton candy is usually sold and made at...</td>\n",
       "      <td>&lt;SOS&gt; Suikerspinnen worden gewoonlijk verkocht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153806</th>\n",
       "      <td>&lt;SOS&gt; At the moment I am looking for a job . &lt;...</td>\n",
       "      <td>&lt;SOS&gt; Op het moment ben ik op zoek naar werk ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153807</th>\n",
       "      <td>&lt;SOS&gt; The unthinkable happened . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; Het ondenkbare is gebeurd . &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153808</th>\n",
       "      <td>&lt;SOS&gt; Let 's wait until she rings . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; Laten we wachten tot ze belt ! &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153809</th>\n",
       "      <td>&lt;SOS&gt; My mom has her hair in a bun . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; Mijn moeder heeft haar haar in een knot ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152194 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ENG_TOKENS  \\\n",
       "0                                              ENG_TOKENS   \n",
       "1                      <SOS> Let 's try something . <EOS>   \n",
       "2                      <SOS> Let 's try something . <EOS>   \n",
       "3                     <SOS> I have to go to sleep . <EOS>   \n",
       "4       <SOS> Today is June 18th and it is Muiriel 's ...   \n",
       "...                                                   ...   \n",
       "153805  <SOS> Cotton candy is usually sold and made at...   \n",
       "153806  <SOS> At the moment I am looking for a job . <...   \n",
       "153807             <SOS> The unthinkable happened . <EOS>   \n",
       "153808          <SOS> Let 's wait until she rings . <EOS>   \n",
       "153809         <SOS> My mom has her hair in a bun . <EOS>   \n",
       "\n",
       "                                               NLD_TOKENS  \n",
       "0                                              NLD_TOKENS  \n",
       "1                    <SOS> Laten we iets proberen ! <EOS>  \n",
       "2                    <SOS> Laat ons iets proberen . <EOS>  \n",
       "3                       <SOS> Ik moet gaan slapen . <EOS>  \n",
       "4       <SOS> Vandaag is het 18 juni en het is de verj...  \n",
       "...                                                   ...  \n",
       "153805  <SOS> Suikerspinnen worden gewoonlijk verkocht...  \n",
       "153806  <SOS> Op het moment ben ik op zoek naar werk ....  \n",
       "153807            <SOS> Het ondenkbare is gebeurd . <EOS>  \n",
       "153808         <SOS> Laten we wachten tot ze belt ! <EOS>  \n",
       "153809  <SOS> Mijn moeder heeft haar haar in een knot ...  \n",
       "\n",
       "[152194 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_SPLIT = 0.9\n",
    "MAX_SIZE = 20\n",
    "FORBIDDEN_CHARS = ['€', '$']\n",
    "\n",
    "\"\"\"Filtering\"\"\"\n",
    "def filter(row):\n",
    "\teng_tokens = row['ENG_TOKENS'].split()\n",
    "\tnld_tokens = row['NLD_TOKENS'].split()\n",
    "\n",
    "\tif (len(eng_tokens) > MAX_SIZE):\n",
    "\t\treturn False\n",
    "    \n",
    "\tif (len(nld_tokens) > MAX_SIZE):\n",
    "\t\treturn False\n",
    "\t\n",
    "\tif any(char in eng_tokens or char in nld_tokens for char in FORBIDDEN_CHARS):\n",
    "\t\treturn False\n",
    "\n",
    "\treturn True\n",
    "\n",
    "df = df[df.apply(filter, axis=1)]\n",
    "\n",
    "print('Total rows from file:', len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocab size: 8390\n",
      "Dutch vocab size: 9715\n"
     ]
    }
   ],
   "source": [
    "from utils.Vocabulary import Vocabulary\n",
    "\n",
    "\"\"\"Create a vocabulary to lookup indices\"\"\"\n",
    "eng_vocab = Vocabulary('ENG')\n",
    "nld_vocab = Vocabulary('NLD')\n",
    "\n",
    "for sentence in df['ENG_TOKENS']:\n",
    "    eng_vocab.add_sentence(sentence)\n",
    "\n",
    "for sentence in df['NLD_TOKENS']:\n",
    "    nld_vocab.add_sentence(sentence)\n",
    "\n",
    "eng_vocab.trim()\n",
    "nld_vocab.trim()\n",
    "\n",
    "\n",
    "print('English vocab size:', len(eng_vocab))\n",
    "print('Dutch vocab size:', len(nld_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtr shape: torch.Size([152194, 20])\n",
      "Random vector:\n",
      "[1, 233, 2920, 149, 557, 205, 738, 48, 49, 1991, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 505, 3255, 155, 169, 18, 126, 1161, 55, 22, 2235, 11, 2, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "['<SOS>', 'One', 'million', 'people', 'lost', 'their', 'lives', 'in', 'the', 'war', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "['<SOS>', 'Een', 'miljoen', 'mensen', 'hebben', 'het', 'leven', 'gelaten', 'in', 'de', 'oorlog', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "pad_index = 0 # Same for both ENG and NLD\n",
    "\n",
    "\"\"\"Vectorize tokens\"\"\"\n",
    "def build_dataset(dataset):\n",
    "\tX, Y = [], []\n",
    "        \n",
    "\tfor _, row in dataset.iterrows():\n",
    "\t\teng_ixs = eng_vocab.lookup_indices(row['ENG_TOKENS'].split())\n",
    "\t\teng_ixs = eng_ixs + [pad_index] * (MAX_SIZE - len(eng_ixs))\n",
    "\t\tX.append(eng_ixs)\n",
    "\n",
    "\t\tnld_ixs = nld_vocab.lookup_indices(row['NLD_TOKENS'].split())\n",
    "\t\tnld_ixs = nld_ixs + [pad_index] * (MAX_SIZE - len(nld_ixs))\n",
    "\t\tY.append(nld_ixs)\n",
    "\n",
    "\t# Convert python arrays to PyTorch tensors\n",
    "\treturn torch.tensor(X, dtype=torch.long), torch.tensor(Y, dtype=torch.long)\n",
    "\n",
    "X, Y = build_dataset(df)\n",
    "\n",
    "import random\n",
    "\n",
    "print('Xtr shape:', X.shape)\n",
    "print('Random vector:')\n",
    "ix = random.randint(0, len(X))\n",
    "print(X[ix].tolist())\n",
    "print(Y[ix].tolist())\n",
    "print()\n",
    "print(eng_vocab.lookup_tokens(X[ix].tolist()))\n",
    "print(nld_vocab.lookup_tokens(Y[ix].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameters: \"\"\"\n",
    "\n",
    "# Model parameters\n",
    "emb_dim       = 300\n",
    "hidden_size   = 250 # The same hidden size for encoder and decoder\n",
    "num_layers    =   2\n",
    "dropout       = 0.1\n",
    "\n",
    "# Training parameters\n",
    "batch_size    = 64\n",
    "iterations    = 50000\n",
    "learning_rate = 0.0001 # The lower the batch size, the lower the learning rate\n",
    "weight_decay  = 0 # Penalize complexity by couting weights into the loss function\n",
    "step_size     = 50000 # Period of learning rate decay\n",
    "gamma         = 0.1 # Multiplicative factor of learning rate decay\n",
    "ft_start_ratio = 0.9\n",
    "ft_final_ratio = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 11367465\n"
     ]
    }
   ],
   "source": [
    "from RNN.Seq2Seq import Seq2Seq\n",
    "\n",
    "\"\"\" Construct the model \"\"\"\n",
    "model = Seq2Seq(\n",
    "    len(eng_vocab),\n",
    "    len(nld_vocab),\n",
    "    emb_dim,\n",
    "    hidden_size,\n",
    "    hidden_size,\n",
    "    num_layers,\n",
    "    dropout,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "print(\"Total parameters:\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # Loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay) # Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions for the training loop\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" Calculate a teaching ratio, starts with a high ratio and lowers throughout training \"\"\"\n",
    "def get_forced_teaching_ratio(current_epoch, total_epochs):\n",
    "    progress = current_epoch / total_epochs\n",
    "    return ft_start_ratio - (ft_start_ratio - ft_final_ratio) * progress\n",
    "\n",
    "\"\"\" Calculate loss on train and test data \"\"\"\n",
    "def log_statistics(eval_batch_size=64):\n",
    "\n",
    "    inputs = torch.zeros((eval_batch_size, MAX_SIZE), dtype=torch.long).to(device)\n",
    "    inputs[:, 0] = 1 # <SOS> has index of 1\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "    \n",
    "        # Sample the models performence on a subset of training data\n",
    "        ix = torch.randint(0, Xtr.shape[0], (eval_batch_size,))\n",
    "        Xb, Yb = Xtr[ix].to(device), Ytr[ix].to(device)\n",
    "        \n",
    "        outputs = model(Xb, inputs)\n",
    "        train_loss = criterion(outputs, Yb)\n",
    "\n",
    "\n",
    "        # Sample the models performence on a subset of testing data\n",
    "        ix = torch.randint(0, Xte.shape[0], (eval_batch_size,))\n",
    "        Xb, Yb = Xte[ix].to(device), Yte[ix].to(device)\n",
    "\n",
    "        outputs = model(Xb, inputs)\n",
    "        test_loss = criterion(outputs, Yb)\n",
    "        \n",
    "        \n",
    "        return train_loss.item(), test_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from ray import tune\n",
    "\n",
    "from RNN.Seq2Seq import Seq2Seq\n",
    "\n",
    "iterations = 50000 # Non-tunable for now\n",
    "\n",
    "\"\"\" Training function for hyper parameter tuning \"\"\"\n",
    "def train_model(config):\n",
    "    # Step 1: Create TensorDataset from X and Y\n",
    "    dataset = TensorDataset(X, Y)\n",
    "\n",
    "    # Step 2: Split dataset into training and testing sets (80% train, 20% test)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    # Step 3: Create DataLoaders for training and testing\n",
    "    batch_size = 64\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize model\n",
    "    model = Seq2Seq(\n",
    "        len(eng_vocab),\n",
    "        len(nld_vocab),\n",
    "        emb_dim,\n",
    "        hidden_size,\n",
    "        hidden_size,\n",
    "        num_layers,\n",
    "        dropout=config[\"dropout\"],\n",
    "    ).to(device)\n",
    "    \n",
    "    # Initialize loss function, optimizer, and learning rate scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "    # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config[\"step_size\"], gamma=config[\"step_size_gamma\"])\n",
    "\n",
    "    train_loader_iter = iter(train_loader) # Iterator for the DataLoader\n",
    "\n",
    "    # Step a pre-defined amount of times\n",
    "    for i in range(iterations):\n",
    "        print(next(train_loader_iter))\n",
    "        Xb, Yb = next(train_loader_iter)\n",
    "        Xb, Yb = Xb.to(device), Yb.to(device)\n",
    "        ft_ratio = get_forced_teaching_ratio(i, iterations)\n",
    "        \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(Xb, Yb, ft_ratio)\n",
    "        loss = criterion(output, Yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "\n",
    "        # Report the average MSE to Ray Tune every so often\n",
    "        if ((i + 1) % (iterations / 50) == 0):\n",
    "            model.eval()\n",
    "            total_mse = 0\n",
    "            with torch.inference_mode():\n",
    "                for batch in test_loader:\n",
    "                    Xb, Yb = batch\n",
    "                    Xb, Yb = Xb.to(device), Yb.to(device)\n",
    "\n",
    "                    output = model(Xb, Yb)\n",
    "                    mse = nn.MSELoss(output, Yb).item()\n",
    "                    total_mse += mse\n",
    "            \n",
    "            avg_mse = total_mse / len(test_loader)\n",
    "            tune.report(iteration=i, mse=avg_mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-24 19:12:59,982\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-10-24 20:52:44</td></tr>\n",
       "<tr><td>Running for: </td><td>01:39:44.33        </td></tr>\n",
       "<tr><td>Memory:      </td><td>17.5/31.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 25600.000: None | Iter 12800.000: None | Iter 6400.000: None | Iter 3200.000: None | Iter 1600.000: None | Iter 800.000: None | Iter 400.000: None | Iter 200.000: None | Iter 100.000: None<br>Logical resource usage: 5.0/24 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 5<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                                          </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_389a8_00000</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-10-24_18-53-56_886860_42744/artifacts/2024-10-24_19-13-00/train_model_2024-10-24_19-13-00/driver_artifacts/train_model_389a8_00000_0_batch_size=32,dropout=0.2115,lr=0.0003,weight_decay=0.0283_2024-10-24_19-13-02/error.txt </td></tr>\n",
       "<tr><td>train_model_389a8_00002</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-10-24_18-53-56_886860_42744/artifacts/2024-10-24_19-13-00/train_model_2024-10-24_19-13-00/driver_artifacts/train_model_389a8_00002_2_batch_size=128,dropout=0.2756,lr=0.0008,weight_decay=0.0391_2024-10-24_19-13-02/error.txt</td></tr>\n",
       "<tr><td>train_model_389a8_00003</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-10-24_18-53-56_886860_42744/artifacts/2024-10-24_19-13-00/train_model_2024-10-24_19-13-00/driver_artifacts/train_model_389a8_00003_3_batch_size=32,dropout=0.2013,lr=0.0015,weight_decay=0.0003_2024-10-24_19-13-03/error.txt </td></tr>\n",
       "<tr><td>train_model_389a8_00006</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-10-24_18-53-56_886860_42744/artifacts/2024-10-24_19-13-00/train_model_2024-10-24_19-13-00/driver_artifacts/train_model_389a8_00006_6_batch_size=32,dropout=0.3472,lr=0.0001,weight_decay=0.0043_2024-10-24_19-13-03/error.txt </td></tr>\n",
       "<tr><td>train_model_389a8_00008</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-10-24_18-53-56_886860_42744/artifacts/2024-10-24_19-13-00/train_model_2024-10-24_19-13-00/driver_artifacts/train_model_389a8_00008_8_batch_size=64,dropout=0.4475,lr=0.0028,weight_decay=0.0001_2024-10-24_19-13-03/error.txt </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  weight_decay</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_389a8_00001</td><td>RUNNING </td><td>192.168.1.121:54836</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.445411</td><td style=\"text-align: right;\">0.0792894  </td><td style=\"text-align: right;\">   0.00206416 </td></tr>\n",
       "<tr><td>train_model_389a8_00004</td><td>RUNNING </td><td>192.168.1.121:54837</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.495315</td><td style=\"text-align: right;\">0.0672401  </td><td style=\"text-align: right;\">   3.74708e-05</td></tr>\n",
       "<tr><td>train_model_389a8_00005</td><td>RUNNING </td><td>192.168.1.121:54841</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.296397</td><td style=\"text-align: right;\">0.00136544 </td><td style=\"text-align: right;\">   0.00156452 </td></tr>\n",
       "<tr><td>train_model_389a8_00007</td><td>RUNNING </td><td>192.168.1.121:54844</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.358363</td><td style=\"text-align: right;\">0.0100613  </td><td style=\"text-align: right;\">  14.0259     </td></tr>\n",
       "<tr><td>train_model_389a8_00009</td><td>RUNNING </td><td>192.168.1.121:54842</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.257771</td><td style=\"text-align: right;\">0.0436454  </td><td style=\"text-align: right;\"> 124.991      </td></tr>\n",
       "<tr><td>train_model_389a8_00000</td><td>ERROR   </td><td>192.168.1.121:54838</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.211473</td><td style=\"text-align: right;\">0.000289081</td><td style=\"text-align: right;\">   0.0282967  </td></tr>\n",
       "<tr><td>train_model_389a8_00002</td><td>ERROR   </td><td>192.168.1.121:54845</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.275578</td><td style=\"text-align: right;\">0.000798602</td><td style=\"text-align: right;\">   0.039131   </td></tr>\n",
       "<tr><td>train_model_389a8_00003</td><td>ERROR   </td><td>192.168.1.121:54839</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.201269</td><td style=\"text-align: right;\">0.00146492 </td><td style=\"text-align: right;\">   0.000297425</td></tr>\n",
       "<tr><td>train_model_389a8_00006</td><td>ERROR   </td><td>192.168.1.121:54843</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.347245</td><td style=\"text-align: right;\">0.000120381</td><td style=\"text-align: right;\">   0.00433787 </td></tr>\n",
       "<tr><td>train_model_389a8_00008</td><td>ERROR   </td><td>192.168.1.121:54840</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.447494</td><td style=\"text-align: right;\">0.00281628 </td><td style=\"text-align: right;\">   7.08784e-05</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-24 19:45:06,171\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_389a8_00003\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/_private/worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/_private/worker.py\", line 901, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=54839, ip=192.168.1.121, actor_id=a6e7231a633fd8afd358f0ec01000000, repr=train_model)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/tune/trainable/trainable.py\", line 328, in train\n",
      "    result = self.step()\n",
      "             ^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/tune/trainable/function_trainable.py\", line 110, in step\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Should not have reached here. The TuneController should not have scheduled another `train` remote call.It should have scheduled a `stop` instead after the training function exits.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_389a8_00000</td></tr>\n",
       "<tr><td>train_model_389a8_00002</td></tr>\n",
       "<tr><td>train_model_389a8_00003</td></tr>\n",
       "<tr><td>train_model_389a8_00006</td></tr>\n",
       "<tr><td>train_model_389a8_00008</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-24 19:45:54,371\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_389a8_00006\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/_private/worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/_private/worker.py\", line 901, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=54843, ip=192.168.1.121, actor_id=c0da29e2564d410df1fbc3d801000000, repr=train_model)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/tune/trainable/trainable.py\", line 328, in train\n",
      "    result = self.step()\n",
      "             ^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/tune/trainable/function_trainable.py\", line 110, in step\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Should not have reached here. The TuneController should not have scheduled another `train` remote call.It should have scheduled a `stop` instead after the training function exits.\n",
      "2024-10-24 19:46:13,132\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_389a8_00008\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/_private/worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/_private/worker.py\", line 901, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=54840, ip=192.168.1.121, actor_id=73f50ad02fa619e5065af83001000000, repr=train_model)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/tune/trainable/trainable.py\", line 328, in train\n",
      "    result = self.step()\n",
      "             ^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/tune/trainable/function_trainable.py\", line 110, in step\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Should not have reached here. The TuneController should not have scheduled another `train` remote call.It should have scheduled a `stop` instead after the training function exits.\n",
      "2024-10-24 19:46:23,857\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_389a8_00002\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/_private/worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/_private/worker.py\", line 901, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=54845, ip=192.168.1.121, actor_id=6ac9947d531def62fbad0fb301000000, repr=train_model)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/tune/trainable/trainable.py\", line 328, in train\n",
      "    result = self.step()\n",
      "             ^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/tune/trainable/function_trainable.py\", line 110, in step\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Should not have reached here. The TuneController should not have scheduled another `train` remote call.It should have scheduled a `stop` instead after the training function exits.\n",
      "2024-10-24 19:46:33,801\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_389a8_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/_private/worker.py\", line 2745, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/_private/worker.py\", line 901, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=54838, ip=192.168.1.121, actor_id=7269093d2e98b6f4b3fd2f7601000000, repr=train_model)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/tune/trainable/trainable.py\", line 328, in train\n",
      "    result = self.step()\n",
      "             ^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marijn/Projecten/vscode_notebooks/.venv/lib/python3.12/site-packages/ray/tune/trainable/function_trainable.py\", line 110, in step\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Should not have reached here. The TuneController should not have scheduled another `train` remote call.It should have scheduled a `stop` instead after the training function exits.\n",
      "2024-10-24 20:52:09,313\tWARNING util.py:201 -- The `on_step_begin` operation took 5.643 s, which may be a performance bottleneck.\n"
     ]
    }
   ],
   "source": [
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "search_space = {\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),  # Learning rate between 0.0001 and 0.1\n",
    "    \"batch_size\": tune.choice([32, 64, 128]),  # Discrete batch sizes\n",
    "    \"dropout\": tune.uniform(0.2, 0.5),         # Dropout rate between 0.2 and 0.5\n",
    "    \"weight_decay\": tune.loguniform(1e-5, 1e03)\n",
    "}\n",
    "\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"mse\",  # We are now optimizing based on MSE\n",
    "    mode=\"min\",    # Minimize MSE\n",
    "    max_t=50000,  # Maximum number of iterations\n",
    "    grace_period=100,\n",
    "    reduction_factor=2\n",
    ")\n",
    "\n",
    "# Run Ray Tune with the new iteration-based training\n",
    "tuner = tune.run(\n",
    "    train_model,\n",
    "    resources_per_trial={\"cpu\": 1, \"gpu\": 0},  # Adjust for GPU if needed\n",
    "    config=search_space,\n",
    "    num_samples=10,  # Number of hyperparameter configurations to try\n",
    "    scheduler=scheduler\n",
    ")\n",
    "\n",
    "# Get the best result (lowest MSE)\n",
    "best_trial = tuner.get_best_trial(\"mse\", \"min\", \"last\")\n",
    "print(f\"Best trial config: {best_trial.config}\")\n",
    "print(f\"Best trial final validation MSE: {best_trial.last_result['mse']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the figure and the primary y-axis\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(12, 6))\n",
    "plt.grid()\n",
    "\n",
    "# Plot the loss on the primary y-axis\n",
    "ax1.plot(epoch_count, train_loss_values, label='Training Loss')\n",
    "ax1.plot(epoch_count, test_loss_values, label='Test Loss', linestyle='--')\n",
    "ax1.set_xlabel('Iterations')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Loss Progression')\n",
    "\n",
    "# Create the secondary y-axis for the learning rate\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(epoch_count, learning_rates, label='Learning Rate', color='green')\n",
    "ax2.set_ylabel('Learning Rate', color='green')\n",
    "ax2.tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "# Add legends to each y-axis\n",
    "ax1.legend(loc='upper right')\n",
    "ax2.legend(loc='upper left')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/RNN-Attention_24-10-2024.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "if os.path.isfile('../models/RNN-Attention_24-10-2024.pt'):\n",
    "    print('Found saved state dictionary!')\n",
    "    model.load_state_dict(torch.load('../models/RNN-Attention_24-10-2024.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download the tokenizer models from nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "def tokenize_sentence(sentence: str) -> list:\n",
    "    \"\"\"Tokenize a single sentence.\"\"\"\n",
    "    return ['<SOS>'] + word_tokenize(sentence) + ['<EOS>']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def translate(sentence, max_output_length=20):\n",
    "\tinput_tokens = tokenize_sentence(sentence)\n",
    "\tinput_indices = eng_vocab.lookup_indices(input_tokens)\n",
    "\n",
    "\toutput_indices, _ = model.evaluate(input_indices, device, max_output_length)\n",
    "\toutput_tokens = nld_vocab.lookup_tokens(output_indices)\n",
    "\n",
    "\tnew_sentence = ' '.join(output_tokens).capitalize()\n",
    "\tnew_sentence = re.sub(r'\\s+([.,!?])', r'\\1', new_sentence)\n",
    "\n",
    "\treturn new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use model ###\n",
    "\n",
    "print(translate('Go!'))\n",
    "print(translate('It\\'s not Fine.'))\n",
    "print(translate('I\\'m very happy today.'))\n",
    "print(translate('He\\'s very sad.'))\n",
    "print(translate('That man is wearing a white shirt.'))\n",
    "print(translate('He\\'s very afraid of spiders.'))\n",
    "print(translate('He\\'s going home to his wife.'))\n",
    "print(translate('Those guys are walking to work.'))\n",
    "print(translate('I\\'m not going with you today.'))\n",
    "print(translate('My girlfriend will not come over tomorrow.'))\n",
    "print(translate('He bought his friends a present for christmas.'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluateAndShowAttention():\n",
    "\n",
    "    ''' Sample a random sentence from the test data '''\n",
    "    input_tokens = test_data.sample()['ENG_TOKENS'].iloc[0].split()\n",
    "    input_indices = eng_vocab.lookup_indices(input_tokens)\n",
    "\n",
    "    output_indices, attentions = model.evaluate(input_indices, device)\n",
    "    output_indices = output_indices[1:] # Remove single batch dimension\n",
    "    output_tokens = nld_vocab.lookup_tokens(output_indices)\n",
    "\n",
    "    attentions = attentions.cpu().numpy()\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions, cmap='plasma')\n",
    "    fig.colorbar(cax)\n",
    "                       \n",
    "    # Set up axes\n",
    "    ax.set_xticks(range(len(input_tokens)))\n",
    "    ax.set_yticks(range(len(output_tokens)))\n",
    "\n",
    "    ax.set_xticklabels(input_tokens, rotation=90)\n",
    "    ax.set_yticklabels(output_tokens)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateAndShowAttention()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
